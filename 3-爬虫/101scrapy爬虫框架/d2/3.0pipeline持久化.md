# pipeline持久化

1. 在items中写个类，有一个一个的字段
2. 在settings中配置pipeline
   1. 数字越小，优先级越高(低的走了然后把items传给高的)(在process_item中)
3. piplines.py
   1. 类 (括号代表的是执行的顺序)
      1. init (1)
         1. 可以接受from_crawler传过来的东西
      2. from_crawler (0)
         1. 这个是类的创建前，可以吧东西放到init中
            1. 使用retuen cls(aa,bb)
            2. 这样init时就会收到aa和bb
         2. 也可以直接用这个去导入设置
            1. aa = #TODO
      3. open_spider (2)
         1. 这个是爬虫开始运行的时候执行的东西
         2. 我们可以在这里进行连接数据库，打开文本什么的
      4. close_spider (4)
         1. 这里是爬虫结束运行的时候执行的东西
         2. 我们可以在这里进行数据库关闭连接，或者文本关闭什么的
      5. process_item (3)
         1. 我们一般都是在这里进行保存东西，例如保存到数据库
         2. return是有区别的，如果是item下一个才能拿到item


<CommentService/>
