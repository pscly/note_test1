# 08.0.分布式

> 概念 ： 可以创建分布式集群，让他们对同一组网络资源进行联合且分布的数据爬取

## 实现

注意:

1. 原生scrapy不能实现
    1. 调度器无法被分布式集群共享
    2. 管道无法被共享
2. 使用 scrapy-redis 组件结合scrapy实现分布式
    1. 它的作用就是提供可以被共享的管道和调度器

## 开始 

创建工程

```bash
scrapy startproject myspider
cd myspider
scrapy genspider myspider www.xxx.com
```

```python
scrapy genspider -t crawl myspider www.xxx.com  # 这里的-t是指定爬虫的类型(不用管，就用上面的就好了)
```

### 修改爬虫文件

1. 导包
    1. `from scrapy_redis.spiders import RedisCrawlSpider`
2. 修改爬虫的父类为倒过来的包
3. 将start_urls替换成redis_key
     1. redis_key = '调度器队列名称'
4. 编写正常的爬虫      

### 修改settings配置文件

### 配置redis的配置文件

redis配置文件位于 `$project_path/redis.conf`

或者位于redis下面的 `redis.conf`

1. 关闭默认绑定: 
    1. 注掉56 行 #bind 127.0.0.1  
    2. 如果不注掉，那么就不能远程连接
2. 关闭保护模型
    1.  修改75行 protected-mode no
    2.  如果不改的话远程只能看不能改

### 启动redis服务端与客户端

`redis-server ./redis.conf  `

`redis-cli`

### 执行当前工程

`scrapy crawl myspider`
`
### 向调度器的队列中放入一个起始的url

1. 在redis客户端
    1. `lpush myspider:start_urls http://www.xxx.com`       # 这里的myspider:start_urls是redis的队列名称

<CommentService/>
